{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtaining Data\n",
    "\n",
    "To follow along and practice with the course resources, I will scrape Twitter data and try to apply the different tools to my own dataset.\n",
    "\n",
    "1. I will first scrap the tweets of 4 Twitter ML accounts I like (with different audiences and styles). I will extract their last 52 tweets until Thursday 19th, January 2023, 00:00 CT. I extracted the following information:\n",
    "    - Date\n",
    "    - Tweet ID\n",
    "    - Tweet Content\n",
    "    - Tweet Sentiment (obtained with [TextBlob](https://textblob.readthedocs.io/en/dev/))\n",
    "    - If the Tweet contains media\n",
    "    - Number of Views\n",
    "    - Number of Retweets\n",
    "    - Number of Replies\n",
    "    - User\n",
    "    - Number of Followers of the User\n",
    "    - Number of Likes\n",
    "\n",
    "2. I will then obtain the sentiment of the tweets and add it to our features.\n",
    "\n",
    "3. Lastly, I will create a CSV file that will be stored on a [Datasets Notion page](https://florentine-rayon-d99.notion.site/Datasets-88840ad9026047d09c0359327f39efd0) I prepared to store my practice Datasets. The data I'll be creating in this tutorial: [Twitter Data](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/56592100-0105-4d81-869e-29ec562a1f2d/ML-AZ-tweets.csv?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230119%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20230119T054104Z&X-Amz-Expires=86400&X-Amz-Signature=66a6100d43d7003c46a926f27092e95d5c709b13c7e505ea10b0ea619f132c6c&X-Amz-SignedHeaders=host&response-content-disposition=filename%3D%22ML-AZ-tweets.csv%22&x-id=GetObject).\n",
    "\n",
    "> Useful additional link for Sentiment Analysis: https://www.geeksforgeeks.org/twitter-sentiment-analysis-using-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twitter Scrapping \n",
    "\n",
    "I'll use the [snscrape](https://github.com/JustAnotherArchivist/snscrape) Python Library to scrap the Tweets. The Library is not well documented, but here are two great resources to help us use the tool: \n",
    "1. [Scrape Twitter with 5 Lines of Code](https://www.youtube.com/watch?v=PUMMCLrVn8A), Youtube Video by Rob Mulla\n",
    "1. [Scrape Twitter data without Twitter API using SNScrape for timeseries analysis](https://datasciencedojo.com/blog/scrape-twitter-data-using-sncrape/), article found in Data Science Dojo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from tqdm import tqdm # Progress bar: conda install -c conda-forge tqdm\n",
    "import snscrape.modules.twitter as sntwitter # pip install snscrape \n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "\n",
    "def scrape_twitter(username, max_tweets = 50):\n",
    "\n",
    "    def clean_tweet(tweet):\n",
    "        # Utility function to clean tweet text by removing links and special \n",
    "        # characters using simple regex statements.\n",
    "        return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", tweet).split())\n",
    "\n",
    "    # Variables:\n",
    "    scraper = sntwitter.TwitterSearchScraper(f\"from:{username} exclude:retweets exclude:replies\")\n",
    "    tweets = []\n",
    "\n",
    "    for i, tweet in tqdm(enumerate(scraper.get_items()), total = max_tweets):\n",
    "\n",
    "        tweet_sentiment = TextBlob(clean_tweet(tweet.rawContent)).sentiment.polarity\n",
    "\n",
    "        tweet_data = [\n",
    "        tweet.date, \n",
    "        tweet.id, \n",
    "        tweet.rawContent,\n",
    "        tweet_sentiment, \n",
    "        tweet.media != None,\n",
    "        tweet.viewCount, \n",
    "        tweet.retweetCount, \n",
    "        tweet.replyCount, \n",
    "        tweet.user.username, \n",
    "        tweet.user.followersCount,\n",
    "        tweet.likeCount,\n",
    "        ]\n",
    "        tweets.append(tweet_data)\n",
    "        if i > max_tweets:\n",
    "            break\n",
    "    \n",
    "    twitter_data = pd.DataFrame(\n",
    "    tweets, \n",
    "    columns = [\n",
    "        'date', \n",
    "        'id', \n",
    "        'content',\n",
    "        'sentiment',\n",
    "        'has_media',\n",
    "        'views', \n",
    "        'retweets', \n",
    "        'replies',\n",
    "        'user',\n",
    "        'followers',\n",
    "        'likes',\n",
    "    ]\n",
    "    )\n",
    "\n",
    "    return twitter_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "51it [00:01, 27.22it/s]                        \n",
      "51it [00:01, 39.12it/s]                        \n",
      "51it [00:01, 30.67it/s]                        \n",
      "51it [00:01, 29.03it/s]                        \n"
     ]
    }
   ],
   "source": [
    "# Getting tweets from users:\n",
    "tweets_tunguz = scrape_twitter('tunguz')\n",
    "tweets_pau = scrape_twitter('paulabartabajo_')\n",
    "tweets_qb = scrape_twitter('quantumblack')\n",
    "tweets_santiago = scrape_twitter('svpino')\n",
    "\n",
    "tweets = pd.concat([tweets_tunguz, tweets_pau, tweets_qb, tweets_santiago])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>content</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>has_media</th>\n",
       "      <th>views</th>\n",
       "      <th>retweets</th>\n",
       "      <th>replies</th>\n",
       "      <th>user</th>\n",
       "      <th>followers</th>\n",
       "      <th>likes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-19 02:55:22+00:00</td>\n",
       "      <td>1615905729654702083</td>\n",
       "      <td>Accurate.</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>False</td>\n",
       "      <td>3828.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>tunguz</td>\n",
       "      <td>90940</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-19 02:21:00+00:00</td>\n",
       "      <td>1615897079741571072</td>\n",
       "      <td>We are so early. https://t.co/jKdSMlpPMS</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>False</td>\n",
       "      <td>3879.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>tunguz</td>\n",
       "      <td>90940</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-19 00:01:10+00:00</td>\n",
       "      <td>1615861890739220481</td>\n",
       "      <td>Why cool and waste it when you can boil and ta...</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>True</td>\n",
       "      <td>5703.0</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>tunguz</td>\n",
       "      <td>90940</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-18 23:46:44+00:00</td>\n",
       "      <td>1615858256471273472</td>\n",
       "      <td>I barely know what a binary tree is. Is that l...</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>False</td>\n",
       "      <td>8774.0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>tunguz</td>\n",
       "      <td>90940</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-18 23:43:05+00:00</td>\n",
       "      <td>1615857338254241792</td>\n",
       "      <td>Yes, gaslighting is the right term here.</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>False</td>\n",
       "      <td>4754.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>tunguz</td>\n",
       "      <td>90940</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2022-12-28 17:43:39+00:00</td>\n",
       "      <td>1608156739270057985</td>\n",
       "      <td>https://t.co/ni3SEHdGBN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>27219.0</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>svpino</td>\n",
       "      <td>228565</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2022-12-28 13:00:08+00:00</td>\n",
       "      <td>1608085388350062594</td>\n",
       "      <td>7 YouTube videos for anyone starting with mach...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>286276.0</td>\n",
       "      <td>521</td>\n",
       "      <td>48</td>\n",
       "      <td>svpino</td>\n",
       "      <td>228565</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2022-12-27 16:58:45+00:00</td>\n",
       "      <td>1607783052297572352</td>\n",
       "      <td>Who currently has more advanced Computer Visio...</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>False</td>\n",
       "      <td>24248.0</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>svpino</td>\n",
       "      <td>228565</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2022-12-27 13:00:17+00:00</td>\n",
       "      <td>1607723041966161922</td>\n",
       "      <td>Free AI Conference in early January!\\n\\nGuess ...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>True</td>\n",
       "      <td>40529.0</td>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "      <td>svpino</td>\n",
       "      <td>228565</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2022-12-26 23:17:42+00:00</td>\n",
       "      <td>1607516029873168384</td>\n",
       "      <td>It’s so sad to see this person become a Russia...</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>True</td>\n",
       "      <td>52537.0</td>\n",
       "      <td>8</td>\n",
       "      <td>29</td>\n",
       "      <td>svpino</td>\n",
       "      <td>228565</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>208 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        date                   id  \\\n",
       "0  2023-01-19 02:55:22+00:00  1615905729654702083   \n",
       "1  2023-01-19 02:21:00+00:00  1615897079741571072   \n",
       "2  2023-01-19 00:01:10+00:00  1615861890739220481   \n",
       "3  2023-01-18 23:46:44+00:00  1615858256471273472   \n",
       "4  2023-01-18 23:43:05+00:00  1615857338254241792   \n",
       "..                       ...                  ...   \n",
       "47 2022-12-28 17:43:39+00:00  1608156739270057985   \n",
       "48 2022-12-28 13:00:08+00:00  1608085388350062594   \n",
       "49 2022-12-27 16:58:45+00:00  1607783052297572352   \n",
       "50 2022-12-27 13:00:17+00:00  1607723041966161922   \n",
       "51 2022-12-26 23:17:42+00:00  1607516029873168384   \n",
       "\n",
       "                                              content  sentiment  has_media  \\\n",
       "0                                           Accurate.   0.400000      False   \n",
       "1            We are so early. https://t.co/jKdSMlpPMS   0.100000      False   \n",
       "2   Why cool and waste it when you can boil and ta...   0.075000       True   \n",
       "3   I barely know what a binary tree is. Is that l...   0.050000      False   \n",
       "4            Yes, gaslighting is the right term here.   0.285714      False   \n",
       "..                                                ...        ...        ...   \n",
       "47                            https://t.co/ni3SEHdGBN   0.000000      False   \n",
       "48  7 YouTube videos for anyone starting with mach...   0.000000      False   \n",
       "49  Who currently has more advanced Computer Visio...   0.300000      False   \n",
       "50  Free AI Conference in early January!\\n\\nGuess ...   0.333333       True   \n",
       "51  It’s so sad to see this person become a Russia...  -0.250000       True   \n",
       "\n",
       "       views  retweets  replies    user  followers  likes  \n",
       "0     3828.0         1        1  tunguz      90940     15  \n",
       "1     3879.0         1        4  tunguz      90940     35  \n",
       "2     5703.0         6        9  tunguz      90940     56  \n",
       "3     8774.0         0       11  tunguz      90940     46  \n",
       "4     4754.0         2        2  tunguz      90940     12  \n",
       "..       ...       ...      ...     ...        ...    ...  \n",
       "47   27219.0         9       16  svpino     228565     45  \n",
       "48  286276.0       521       48  svpino     228565   2025  \n",
       "49   24248.0         3       18  svpino     228565     18  \n",
       "50   40529.0        26        4  svpino     228565    158  \n",
       "51   52537.0         8       29  svpino     228565    182  \n",
       "\n",
       "[208 rows x 11 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.to_csv(\"ML-AZ-tweets.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('vscode_ds_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c6e3ccdc3ac37e01317e6f0ad7e22b7f72a2fba3a7384ffa8ab2b4b7f9d3829d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
